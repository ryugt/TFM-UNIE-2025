# Guarda este c√≥digo en un archivo llamado pipeline.py

import subprocess
import os
import time

# --- Nombres de los archivos intermedios y finales ---
# Puedes ajustar estos nombres si tus scripts usan otros por defecto.
FILE_JOINED = 'cicids2017_completo.csv'
FILE_CLEANED_1 = 'cicids2017_reducido.csv'
FILE_CLASSIFIED = 'cicids2017_clasificado.csv'
FILE_CLEANED_2 = 'cicids2017_clasificado_limpio.csv'
FILE_BALANCED = 'cicids2017_balanceado.csv'
FILE_JSONL = 'cicids2017_autotrain_full.jsonl'
BASE_STRATIFIED = ['train', 'val', 'test'] # Prefijos para los 3 archivos de salida

def run_script(script_name, description):
    """Funci√≥n para ejecutar un script y manejar errores."""
    print(f"--- PASO: {description} ---")
    print(f"Ejecutando '{script_name}'...")
    try:
        # Ejecuta el script. check=True hace que falle si el script da un error.
        subprocess.run(['python', script_name], check=True)
        print(f"'{script_name}' completado con √©xito.\n")
        time.sleep(1) # Peque√±a pausa
    except FileNotFoundError:
        print(f"Error: No se encontr√≥ el script '{script_name}'. Aseg√∫rate de que est√° en el mismo directorio.")
        exit()
    except subprocess.CalledProcessError:
        print(f"Error: El script '{script_name}' fall√≥ durante su ejecuci√≥n.")
        exit()

def main():
    """Funci√≥n principal que orquesta todo el pipeline."""
    start_time = time.time()
    print("üöÄ Iniciando pipeline de procesamiento de datos...\n")

    # NOTA: Este pipeline asume que cada script ya sabe qu√© archivo de entrada
    # leer y qu√© archivo de salida escribir. Por ejemplo, que 'dataset_clean.py'
    # busca y lee el archivo generado por 'datasets_joiner.py'.

    # 1. Uni√≥n de CSVs
    run_script('datasets_joiner.py', 'Uni√≥n de archivos CSV del dataset')

    # 2. Primera limpieza
    run_script('dataset_clean.py', 'Primera limpieza de datos')

    # 3. Clasificaci√≥n
    run_script('dataset_classification.py', 'Clasificaci√≥n de datos')

    # 4. Segunda limpieza
    run_script('dataset_second_cleaning.py', 'Segunda limpieza de datos')

    # 5. Balanceo de datos
    run_script('dataset_balanced.py', 'Balanceo del dataset')

    # 6. Conversi√≥n de CSV a JSONL
    run_script('dataset_csv_to_jsonl.py', 'Conversi√≥n a formato JSONL')

    # 7. Estratificaci√≥n (Train/Val/Test)
    run_script('dataset_stratification.py', 'Estratificaci√≥n en train, val y test')

    # 8. Limpieza Sem√°ntica
    run_script('dataset_semantic_clean.py', 'Limpieza sem√°ntica de los sets')

    # 9. Enriquecimiento Sem√°ntico Final
    run_script('dataset_semantic_enricher_english_v2.py', 'Enriquecimiento sem√°ntico final')

    end_time = time.time()
    print(f"‚úÖ Pipeline completado en {end_time - start_time:.2f} segundos.")
    print("Los archivos finales enriquecidos para el entrenamiento est√°n listos.")


if __name__ == '__main__':
    main()